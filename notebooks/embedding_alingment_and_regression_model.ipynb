{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa65ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "BASEPATH_RESOURCES = \"../resources/\"\n",
    "BASEPATH_EMBEDDINGS = os.path.join(BASEPATH_RESOURCES, \"word_embeddings/\")\n",
    "BASEPATH_XANEW = os.path.join(BASEPATH_RESOURCES, \"XANEW_lexicon/\")\n",
    "WORD_EMBEDDINGS_FILENAME_TEMPLATE = os.path.join(BASEPATH_EMBEDDINGS, \"{}-w.npy\")\n",
    "VOCAB_FILENAME_TEMPLATE = os.path.join(BASEPATH_EMBEDDINGS, \"{}-vocab.pkl\")\n",
    "FULLY_AVAILABLE_FILENAME = \"histWord_fullAvail_1800.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c68825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For accessing modules from parent folder from jupyter notebook\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c41b1",
   "metadata": {},
   "source": [
    "Secondary distribution of the Warringer et al. XANEW valence-lexicon provided by Buchel el al.: https://github.com/JULIELab/XANEW . We are only interested in the valence dimension of the provided VAD-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b32bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "aardvark       6.26\n",
       "abalone        5.30\n",
       "abandon        2.84\n",
       "abandonment    2.63\n",
       "abbey          5.85\n",
       "               ... \n",
       "zone           4.75\n",
       "zoning         4.65\n",
       "zoo            7.00\n",
       "zoom           5.86\n",
       "zucchini       6.30\n",
       "Name: valence, Length: 13915, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xanew_csv_location = os.path.join(BASEPATH_XANEW, 'Ratings_Warriner_et_al.csv')\n",
    "df_xanew = pd.read_csv(xanew_csv_location, index_col=0)\n",
    "df_xanew=df_xanew[['Word','V.Mean.Sum', 'A.Mean.Sum', 'D.Mean.Sum']]\n",
    "df_xanew.columns=['word', 'valence', 'arousal', 'dominance']\n",
    "df_xanew.set_index('word',inplace=True)\n",
    "df_xanew = df_xanew['valence']\n",
    "df_xanew = df_xanew[0:]\n",
    "df_xanew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf764224",
   "metadata": {},
   "source": [
    "For training a regression model that predicts valence-scores based on word embeddings, contemporary word-embeddings and the (contemporary) XANEW lexicon are used. The contemporary word-ebmeddings provided by Kozlowski et al. (https://github.com/KnowledgeLab/GeometryofCulture) are trained on the Google Books Ngram Dataset (like the historical word-embeddings) and use data from 2000-2012. As the original ANEW lexicon was published in 1999 and XANEW was published in 2013, this seems an appropriate time period.\n",
    "\n",
    "The contemporary word-embeddings come in a 5gb file, so in order to save RAM they are read chunk-wise and only those words that are present in the subset of fully available words in the historical embeddings (meaning words that are available from a given start-year and throughout all following decades) OR that are present in the XANEW dataset are kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d376ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>0.363338</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>-0.198817</td>\n",
       "      <td>0.310261</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>-0.295411</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>0.328381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056671</td>\n",
       "      <td>0.145127</td>\n",
       "      <td>0.231035</td>\n",
       "      <td>0.068239</td>\n",
       "      <td>-0.191126</td>\n",
       "      <td>0.050652</td>\n",
       "      <td>0.140522</td>\n",
       "      <td>-0.099371</td>\n",
       "      <td>0.229379</td>\n",
       "      <td>-0.112136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>0.418176</td>\n",
       "      <td>-0.116714</td>\n",
       "      <td>0.270946</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>0.245896</td>\n",
       "      <td>-0.118507</td>\n",
       "      <td>0.086045</td>\n",
       "      <td>0.247306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175549</td>\n",
       "      <td>-0.097769</td>\n",
       "      <td>0.478173</td>\n",
       "      <td>0.203049</td>\n",
       "      <td>-0.128923</td>\n",
       "      <td>-0.112181</td>\n",
       "      <td>0.162362</td>\n",
       "      <td>-0.268262</td>\n",
       "      <td>0.136539</td>\n",
       "      <td>-0.264232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>0.471927</td>\n",
       "      <td>0.205140</td>\n",
       "      <td>-0.224204</td>\n",
       "      <td>-0.848070</td>\n",
       "      <td>-0.182479</td>\n",
       "      <td>0.067136</td>\n",
       "      <td>-0.584827</td>\n",
       "      <td>-0.059551</td>\n",
       "      <td>0.181575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100134</td>\n",
       "      <td>0.343926</td>\n",
       "      <td>0.225350</td>\n",
       "      <td>0.153648</td>\n",
       "      <td>-0.031483</td>\n",
       "      <td>-0.382292</td>\n",
       "      <td>0.358430</td>\n",
       "      <td>-0.526325</td>\n",
       "      <td>-0.065493</td>\n",
       "      <td>-0.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>-0.019393</td>\n",
       "      <td>0.107880</td>\n",
       "      <td>-0.075585</td>\n",
       "      <td>-0.377154</td>\n",
       "      <td>-0.229693</td>\n",
       "      <td>-0.107939</td>\n",
       "      <td>-0.318801</td>\n",
       "      <td>-0.612747</td>\n",
       "      <td>0.340766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.322502</td>\n",
       "      <td>0.196349</td>\n",
       "      <td>-0.151370</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>-0.182635</td>\n",
       "      <td>-0.104195</td>\n",
       "      <td>-0.173470</td>\n",
       "      <td>-0.165159</td>\n",
       "      <td>-0.096662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>0.212165</td>\n",
       "      <td>0.260075</td>\n",
       "      <td>0.237165</td>\n",
       "      <td>-0.006635</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>-0.182506</td>\n",
       "      <td>-0.045717</td>\n",
       "      <td>-0.039354</td>\n",
       "      <td>0.214503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288301</td>\n",
       "      <td>0.241163</td>\n",
       "      <td>0.217152</td>\n",
       "      <td>-0.055507</td>\n",
       "      <td>-0.274351</td>\n",
       "      <td>0.356617</td>\n",
       "      <td>0.084031</td>\n",
       "      <td>-0.269011</td>\n",
       "      <td>0.041584</td>\n",
       "      <td>0.096775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21188</th>\n",
       "      <td>cockamamie</td>\n",
       "      <td>0.233569</td>\n",
       "      <td>0.091536</td>\n",
       "      <td>-0.056433</td>\n",
       "      <td>-0.228170</td>\n",
       "      <td>-0.163259</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.098792</td>\n",
       "      <td>-0.089111</td>\n",
       "      <td>-0.089200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.180473</td>\n",
       "      <td>0.241582</td>\n",
       "      <td>-0.025437</td>\n",
       "      <td>-0.043793</td>\n",
       "      <td>-0.096972</td>\n",
       "      <td>0.117947</td>\n",
       "      <td>-0.174045</td>\n",
       "      <td>-0.061766</td>\n",
       "      <td>-0.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21189</th>\n",
       "      <td>amaretto</td>\n",
       "      <td>0.158590</td>\n",
       "      <td>0.048587</td>\n",
       "      <td>-0.067799</td>\n",
       "      <td>-0.153656</td>\n",
       "      <td>-0.186635</td>\n",
       "      <td>-0.043126</td>\n",
       "      <td>-0.172249</td>\n",
       "      <td>-0.137021</td>\n",
       "      <td>-0.056120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002677</td>\n",
       "      <td>0.078793</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.032037</td>\n",
       "      <td>-0.136778</td>\n",
       "      <td>-0.041912</td>\n",
       "      <td>-0.044062</td>\n",
       "      <td>0.092137</td>\n",
       "      <td>0.038940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190</th>\n",
       "      <td>dogface</td>\n",
       "      <td>0.159761</td>\n",
       "      <td>-0.002160</td>\n",
       "      <td>-0.031744</td>\n",
       "      <td>-0.120493</td>\n",
       "      <td>-0.108183</td>\n",
       "      <td>0.036673</td>\n",
       "      <td>-0.071997</td>\n",
       "      <td>-0.068909</td>\n",
       "      <td>-0.052637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.074484</td>\n",
       "      <td>0.051996</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>-0.034385</td>\n",
       "      <td>-0.039118</td>\n",
       "      <td>-0.010991</td>\n",
       "      <td>0.042650</td>\n",
       "      <td>0.060248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21191</th>\n",
       "      <td>applejack</td>\n",
       "      <td>0.136554</td>\n",
       "      <td>0.065858</td>\n",
       "      <td>-0.160253</td>\n",
       "      <td>-0.120877</td>\n",
       "      <td>-0.135318</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>-0.027766</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>-0.066428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.116637</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>-0.088599</td>\n",
       "      <td>-0.083506</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>-0.067914</td>\n",
       "      <td>-0.052102</td>\n",
       "      <td>0.008748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21192</th>\n",
       "      <td>dippy</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>-0.062361</td>\n",
       "      <td>-0.137275</td>\n",
       "      <td>-0.084821</td>\n",
       "      <td>-0.005470</td>\n",
       "      <td>-0.042211</td>\n",
       "      <td>-0.100386</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.149945</td>\n",
       "      <td>-0.026690</td>\n",
       "      <td>0.041329</td>\n",
       "      <td>-0.056321</td>\n",
       "      <td>-0.080217</td>\n",
       "      <td>0.036068</td>\n",
       "      <td>-0.079353</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>0.022094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21193 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word        V1        V2        V3        V4        V5        V6   \n",
       "0             the  0.246731  0.363338  0.060991 -0.198817  0.310261  0.009408  \\\n",
       "1              of  0.093149  0.418176 -0.116714  0.270946  0.204331  0.245896   \n",
       "2              to  0.471927  0.205140 -0.224204 -0.848070 -0.182479  0.067136   \n",
       "3             and -0.019393  0.107880 -0.075585 -0.377154 -0.229693 -0.107939   \n",
       "4               a  0.212165  0.260075  0.237165 -0.006635  0.019352 -0.182506   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "21188  cockamamie  0.233569  0.091536 -0.056433 -0.228170 -0.163259  0.042050   \n",
       "21189    amaretto  0.158590  0.048587 -0.067799 -0.153656 -0.186635 -0.043126   \n",
       "21190     dogface  0.159761 -0.002160 -0.031744 -0.120493 -0.108183  0.036673   \n",
       "21191   applejack  0.136554  0.065858 -0.160253 -0.120877 -0.135318  0.040741   \n",
       "21192       dippy  0.035270  0.017017 -0.062361 -0.137275 -0.084821 -0.005470   \n",
       "\n",
       "             V7        V8        V9  ...      V291      V292      V293   \n",
       "0     -0.295411 -0.006240  0.328381  ... -0.056671  0.145127  0.231035  \\\n",
       "1     -0.118507  0.086045  0.247306  ...  0.175549 -0.097769  0.478173   \n",
       "2     -0.584827 -0.059551  0.181575  ... -0.100134  0.343926  0.225350   \n",
       "3     -0.318801 -0.612747  0.340766  ...  0.020978  0.322502  0.196349   \n",
       "4     -0.045717 -0.039354  0.214503  ... -0.288301  0.241163  0.217152   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21188  0.098792 -0.089111 -0.089200  ... -0.049771  0.180473  0.241582   \n",
       "21189 -0.172249 -0.137021 -0.056120  ... -0.002677  0.078793  0.086313   \n",
       "21190 -0.071997 -0.068909 -0.052637  ...  0.073368  0.074484  0.051996   \n",
       "21191 -0.027766 -0.119300 -0.066428  ...  0.040380  0.116637  0.084052   \n",
       "21192 -0.042211 -0.100386 -0.039544  ...  0.050761  0.149945 -0.026690   \n",
       "\n",
       "           V294      V295      V296      V297      V298      V299      V300  \n",
       "0      0.068239 -0.191126  0.050652  0.140522 -0.099371  0.229379 -0.112136  \n",
       "1      0.203049 -0.128923 -0.112181  0.162362 -0.268262  0.136539 -0.264232  \n",
       "2      0.153648 -0.031483 -0.382292  0.358430 -0.526325 -0.065493 -0.254600  \n",
       "3     -0.151370  0.021184 -0.182635 -0.104195 -0.173470 -0.165159 -0.096662  \n",
       "4     -0.055507 -0.274351  0.356617  0.084031 -0.269011  0.041584  0.096775  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21188 -0.025437 -0.043793 -0.096972  0.117947 -0.174045 -0.061766 -0.068300  \n",
       "21189  0.017446  0.032037 -0.136778 -0.041912 -0.044062  0.092137  0.038940  \n",
       "21190  0.018723  0.007258 -0.034385 -0.039118 -0.010991  0.042650  0.060248  \n",
       "21191  0.005058 -0.088599 -0.083506  0.017294 -0.067914 -0.052102  0.008748  \n",
       "21192  0.041329 -0.056321 -0.080217  0.036068 -0.079353  0.016373  0.022094  \n",
       "\n",
       "[21193 rows x 301 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds2012filename = os.path.join(BASEPATH_EMBEDDINGS, \"US_Ngrams_2000_12.csv\")\n",
    "vocab_xanew_set = set(df_xanew.index)\n",
    "\n",
    "with open(os.path.join(BASEPATH_EMBEDDINGS, FULLY_AVAILABLE_FILENAME), 'rb') as f:\n",
    "    data_fully_available = pickle.load(f)\n",
    "vocab_fully_available = set(data_fully_available['1990'][\"word\"]) #doesn't actually matter which year as long as it is present\n",
    "\n",
    "#filtered_xanew_vocab = set(df_xanew.index[df_xanew.index.isin(vocab_fully_available)])\n",
    "\n",
    "chunks = []\n",
    "condition = lambda x: x.iloc[0] in vocab_xanew_set or x.iloc[0] in vocab_fully_available \n",
    "for chunk in pd.read_csv(embeds2012filename, chunksize=10000):\n",
    "    filtered_chunk = chunk[chunk.apply(condition, axis=1)]\n",
    "    chunks.append(filtered_chunk)\n",
    "\n",
    "embeds2012df = pd.concat(chunks, ignore_index=True)\n",
    "embeds2012df.rename(columns={embeds2012df.columns[0]: 'word'}, inplace=True)\n",
    "embeds2012df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b6b3f",
   "metadata": {},
   "source": [
    "Saving the 2012 data to disk in the same format as the historical word-embeddings in order to be able to use the embedding-space-alignment code provided by Hamilton et al. . This will be used to align the 2012 embedding to the historical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d454cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_FILENAME_TEMPLATE.format(\"2012\"), 'wb') as f:\n",
    "    pickle.dump(list(embeds2012df[\"word\"]), f)\n",
    "    \n",
    "with open(WORD_EMBEDDINGS_FILENAME_TEMPLATE.format(\"2012\"), 'wb') as f:\n",
    "    np.save(f, embeds2012df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb570c",
   "metadata": {},
   "source": [
    "Aligning the 2012-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104e5f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading year: 1990\n",
      "Aligning year: 1990\n",
      "Writing year: 1990\n",
      "Loading year: 2012\n",
      "Aligning year: 2012\n",
      "Writing year: 2012\n"
     ]
    }
   ],
   "source": [
    "#embedding-space-alignment from: \n",
    "#https://github.com/williamleif/histwords/blob/31e4d200310ebd4051776828eccb8b60c2120427/vecanalysis/seq_procrustes.py\n",
    "\n",
    "from vecanalysis import alignment\n",
    "from representations.representation_factory import create_representation\n",
    "from ioutils import write_pickle, words_above_count, mkdir\n",
    "\n",
    "embeds2012filename = os.path.join(BASEPATH_EMBEDDINGS, \"US_Ngrams_2000_12.csv\")\n",
    "\n",
    "def align_years(years, rep_type, in_dir, out_dir, words, **rep_args):\n",
    "    first_iter = True\n",
    "    base_embed = None\n",
    "    for year in years:\n",
    "        print(\"Loading year:\", year)\n",
    "        year_embed = create_representation(rep_type, in_dir + str(year), **rep_args)\n",
    "        year_words = words[str(year)]\n",
    "        year_embed.get_subembed(year_words)\n",
    "        print(\"Aligning year:\", year)\n",
    "        if first_iter:\n",
    "            aligned_embed = year_embed\n",
    "            first_iter = False\n",
    "        else:\n",
    "            aligned_embed = alignment.smart_procrustes_align(base_embed, year_embed)\n",
    "        base_embed = aligned_embed\n",
    "        print(\"Writing year:\", year)\n",
    "        foutname = out_dir + str(year)\n",
    "        np.save(foutname + \"-w.npy\",aligned_embed.m)\n",
    "        write_pickle(aligned_embed.iw, foutname + \"-vocab.pkl\")\n",
    "        \n",
    "align_years([1990, 2012], 'word2vec', BASEPATH_EMBEDDINGS, BASEPATH_EMBEDDINGS + \"aligned_\", {'1990': vocab_fully_available, '2012': list(embeds2012df['word'])})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2afbf",
   "metadata": {},
   "source": [
    "Deleting the old non-aligned 2012 embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1fb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds2012df, chunks = [], []\n",
    "\n",
    "os.remove(WORD_EMBEDDINGS_FILENAME_TEMPLATE.format(\"2012\"))\n",
    "os.remove(VOCAB_FILENAME_TEMPLATE.format(\"2012\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4893c730",
   "metadata": {},
   "source": [
    "Now that the 2012 embeddings have been aligned, a regression model that predicts valence-scores from word-embeddings can be trained, using the 2012 embeddings and the XANEW lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61321f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>be</td>\n",
       "      <td>-0.073921</td>\n",
       "      <td>-0.017005</td>\n",
       "      <td>0.041815</td>\n",
       "      <td>-0.0618</td>\n",
       "      <td>-0.027994</td>\n",
       "      <td>0.062716</td>\n",
       "      <td>-0.049718</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>-0.016903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049053</td>\n",
       "      <td>0.056376</td>\n",
       "      <td>-0.01235</td>\n",
       "      <td>0.045981</td>\n",
       "      <td>0.049847</td>\n",
       "      <td>-0.025249</td>\n",
       "      <td>-0.057048</td>\n",
       "      <td>-0.072376</td>\n",
       "      <td>-0.020001</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>have</td>\n",
       "      <td>-0.085668</td>\n",
       "      <td>-0.017344</td>\n",
       "      <td>-0.060283</td>\n",
       "      <td>-0.05498</td>\n",
       "      <td>-0.007186</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>-0.048267</td>\n",
       "      <td>-0.011891</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012468</td>\n",
       "      <td>0.139748</td>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.014454</td>\n",
       "      <td>-0.050947</td>\n",
       "      <td>-0.043515</td>\n",
       "      <td>0.040321</td>\n",
       "      <td>0.020061</td>\n",
       "      <td>-0.02495</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>do</td>\n",
       "      <td>-0.026111</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.061897</td>\n",
       "      <td>-0.042794</td>\n",
       "      <td>-0.120985</td>\n",
       "      <td>-0.021435</td>\n",
       "      <td>0.045168</td>\n",
       "      <td>-0.020929</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070293</td>\n",
       "      <td>0.152879</td>\n",
       "      <td>-0.038581</td>\n",
       "      <td>-0.06477</td>\n",
       "      <td>-0.029448</td>\n",
       "      <td>0.031269</td>\n",
       "      <td>0.026742</td>\n",
       "      <td>-0.019348</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>one</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>-0.107683</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>-0.060565</td>\n",
       "      <td>-0.003685</td>\n",
       "      <td>-0.040135</td>\n",
       "      <td>-0.037717</td>\n",
       "      <td>-0.027218</td>\n",
       "      <td>0.032969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00091</td>\n",
       "      <td>0.136521</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>-0.072262</td>\n",
       "      <td>-0.034973</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>-0.004832</td>\n",
       "      <td>-0.067237</td>\n",
       "      <td>0.028584</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>can</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>-0.004003</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>-0.015006</td>\n",
       "      <td>-0.067744</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>-0.029684</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037644</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>-0.007332</td>\n",
       "      <td>-0.006802</td>\n",
       "      <td>0.098844</td>\n",
       "      <td>0.054912</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>-0.040598</td>\n",
       "      <td>0.028588</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21188</th>\n",
       "      <td>cockamamie</td>\n",
       "      <td>0.014528</td>\n",
       "      <td>0.040717</td>\n",
       "      <td>0.08493</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>-0.078333</td>\n",
       "      <td>0.054029</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>0.074691</td>\n",
       "      <td>-0.001976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071557</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>0.034515</td>\n",
       "      <td>-0.115798</td>\n",
       "      <td>-0.085939</td>\n",
       "      <td>-0.038124</td>\n",
       "      <td>0.056204</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>-0.072134</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21189</th>\n",
       "      <td>amaretto</td>\n",
       "      <td>0.026179</td>\n",
       "      <td>0.078425</td>\n",
       "      <td>0.041433</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>-0.012127</td>\n",
       "      <td>-0.015286</td>\n",
       "      <td>-0.069652</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>-0.032376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029965</td>\n",
       "      <td>0.105333</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>-0.10273</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>-0.133615</td>\n",
       "      <td>0.03053</td>\n",
       "      <td>-0.105485</td>\n",
       "      <td>-0.019015</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190</th>\n",
       "      <td>dogface</td>\n",
       "      <td>0.061255</td>\n",
       "      <td>0.111247</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>-0.037107</td>\n",
       "      <td>-0.020661</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>-0.008643</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>-0.002511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021859</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.049622</td>\n",
       "      <td>-0.089446</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>-0.132994</td>\n",
       "      <td>0.062472</td>\n",
       "      <td>-0.138655</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21191</th>\n",
       "      <td>applejack</td>\n",
       "      <td>0.03337</td>\n",
       "      <td>0.103647</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>-0.030663</td>\n",
       "      <td>-0.055398</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>-0.024408</td>\n",
       "      <td>0.097765</td>\n",
       "      <td>0.014814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02476</td>\n",
       "      <td>0.080152</td>\n",
       "      <td>0.042838</td>\n",
       "      <td>-0.034143</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.093605</td>\n",
       "      <td>0.101309</td>\n",
       "      <td>-0.036631</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21192</th>\n",
       "      <td>dippy</td>\n",
       "      <td>0.077467</td>\n",
       "      <td>0.074533</td>\n",
       "      <td>-0.020338</td>\n",
       "      <td>-0.07975</td>\n",
       "      <td>-0.050377</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>0.025574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.080281</td>\n",
       "      <td>0.067841</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>-0.099108</td>\n",
       "      <td>0.065647</td>\n",
       "      <td>-0.106881</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13772 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word         1         2         3         4         5         6   \n",
       "10             be -0.073921 -0.017005  0.041815   -0.0618 -0.027994  0.062716  \\\n",
       "21           have -0.085668 -0.017344 -0.060283  -0.05498 -0.007186  0.052359   \n",
       "30             do -0.026111  0.006054 -0.061897 -0.042794 -0.120985 -0.021435   \n",
       "31            one  0.017421 -0.107683  0.010804 -0.060565 -0.003685 -0.040135   \n",
       "40            can  0.010438 -0.004003  0.012444  0.009934 -0.015006 -0.067744   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "21188  cockamamie  0.014528  0.040717   0.08493 -0.006598 -0.078333  0.054029   \n",
       "21189    amaretto  0.026179  0.078425  0.041433 -0.016075 -0.012127 -0.015286   \n",
       "21190     dogface  0.061255  0.111247  0.019108 -0.037107 -0.020661 -0.008131   \n",
       "21191   applejack   0.03337  0.103647  0.026528 -0.030663 -0.055398  0.038067   \n",
       "21192       dippy  0.077467  0.074533 -0.020338  -0.07975 -0.050377  -0.00537   \n",
       "\n",
       "              7         8         9  ...       292       293       294   \n",
       "10    -0.049718 -0.015574 -0.016903  ...  0.049053  0.056376  -0.01235  \\\n",
       "21    -0.048267 -0.011891  0.014289  ...  0.012468  0.139748  0.010565   \n",
       "30     0.045168 -0.020929  0.006951  ... -0.070293  0.152879 -0.038581   \n",
       "31    -0.037717 -0.027218  0.032969  ...  -0.00091  0.136521  0.018862   \n",
       "40     0.025649 -0.029684 -0.010708  ...  0.037644   0.06413 -0.007332   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21188 -0.027264  0.074691 -0.001976  ...  0.071557  0.136786  0.034515   \n",
       "21189 -0.069652  0.026618 -0.032376  ...  0.029965  0.105333  0.064314   \n",
       "21190 -0.008643  0.033557 -0.002511  ... -0.021859 -0.000553  0.049622   \n",
       "21191 -0.024408  0.097765  0.014814  ...   0.02476  0.080152  0.042838   \n",
       "21192  0.005428  0.084321  0.025574  ...  0.008816  0.080281  0.067841   \n",
       "\n",
       "            295       296       297       298       299       300 valence  \n",
       "10     0.045981  0.049847 -0.025249 -0.057048 -0.072376 -0.020001    6.18  \n",
       "21     0.014454 -0.050947 -0.043515  0.040321  0.020061  -0.02495    5.86  \n",
       "30     -0.06477 -0.029448  0.031269  0.026742 -0.019348  0.009928    5.41  \n",
       "31    -0.072262 -0.034973  0.013554 -0.004832 -0.067237  0.028584    6.09  \n",
       "40    -0.006802  0.098844  0.054912  0.026327 -0.040598  0.028588    6.41  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "21188 -0.115798 -0.085939 -0.038124  0.056204  0.005665 -0.072134    4.14  \n",
       "21189  -0.10273  0.008727 -0.133615   0.03053 -0.105485 -0.019015    6.00  \n",
       "21190 -0.089446  0.028525 -0.132994  0.062472 -0.138655 -0.020023    3.95  \n",
       "21191 -0.034143 -0.048138 -0.093605  0.101309 -0.036631  0.034687    5.79  \n",
       "21192 -0.083912  0.036342 -0.099108  0.065647 -0.106881  0.028036    4.26  \n",
       "\n",
       "[13772 rows x 302 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2012 = pickle.load(open(os.path.join(BASEPATH_EMBEDDINGS, \"aligned_2012-vocab.pkl\"), \"rb\"))\n",
    "embeds2012 = np.load(open(os.path.join(BASEPATH_EMBEDDINGS, \"aligned_2012-w.npy\"),  \"rb\"))\n",
    "\n",
    "embeds2012df = pd.DataFrame(np.column_stack((vocab2012, embeds2012)))\n",
    "embeds2012df.rename(columns={embeds2012df.columns[0]: 'word'}, inplace=True)\n",
    "embeds2012df.iloc[:, 1:] = embeds2012df.iloc[:, 1:].astype(float)\n",
    "\n",
    "\n",
    "data = embeds2012df.merge(df_xanew, left_on=embeds2012df.columns[0], right_index=True, how = \"left\")\n",
    "data = data.dropna()\n",
    "\n",
    "#dataframe containig for each word the embeddings as well as the valence-score\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af59df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "aardvark       6.26\n",
       "abalone        5.30\n",
       "abandon        2.84\n",
       "abandonment    2.63\n",
       "abbey          5.85\n",
       "               ... \n",
       "zone           4.75\n",
       "zoning         4.65\n",
       "zoo            7.00\n",
       "zoom           5.86\n",
       "zucchini       6.30\n",
       "Name: valence, Length: 13915, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xanew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e532e",
   "metadata": {},
   "source": [
    "Performing train-test split to check if the model is working as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0547ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786606352703527"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:301], data['valence'], test_size=0.2, random_state=42)\n",
    "testwords = list(X_test['word'])\n",
    "X_train = X_train.drop('word', axis = 1)\n",
    "X_test = X_test.drop('word', axis = 1)\n",
    "\n",
    "reg_traintest = Ridge()\n",
    "reg_traintest.fit(X_train, y_train)\n",
    "preds = reg_traintest.predict(X_test)\n",
    "sklearn.metrics.mean_squared_error(y_test, preds, squared = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b7fecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"regression_model_trainset.pkl\", 'wb') as f:\n",
    "    pickle.dump(reg_traintest, f)\n",
    "    \n",
    "with open(\"testset_words.pkl\", 'wb') as f:\n",
    "    pickle.dump(testwords, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5dd4b",
   "metadata": {},
   "source": [
    "Training model on the full data and saving the result to disk for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71ca574",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Ridge(alpha = 100)\n",
    "reg.fit(data.iloc[:,1:301].to_numpy(), data['valence'])\n",
    "\n",
    "with open(\"../regression_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011f604",
   "metadata": {},
   "source": [
    "All that's left is taking only those words from the 2012 embeddings that are fully available (from the historical startYear throughout the decades) and appending it to the file that currently contains the fully available words + their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfcc65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only words from 2012 embeddings that are also available for the other decades\n",
    "embeds2012df = embeds2012df[embeds2012df['word'].isin(vocab_fully_available)]\n",
    "embeds2012df = embeds2012df.sort_values(by = \"word\")\n",
    "\n",
    "#keeping only words for other decades that are also available for 2012 embeddings\n",
    "reduced_2012_wordset = set(embeds2012df[\"word\"])\n",
    "\n",
    "for year in data_fully_available.keys():    \n",
    "    data_fully_available[year] = data_fully_available[year].loc[data_fully_available[year][\"word\"].isin(reduced_2012_wordset)]\n",
    "    data_fully_available[year] = data_fully_available[year].sort_values(by = \"word\")\n",
    "\n",
    "data_fully_available['2012'] = embeds2012df\n",
    "\n",
    "with open(os.path.join(BASEPATH_RESOURCES, \"fullAvalList.pkl\"), 'wb') as f:\n",
    "    pickle.dump(reduced_2012_wordset, f)\n",
    "\n",
    "with open(os.path.join(BASEPATH_EMBEDDINGS, FULLY_AVAILABLE_FILENAME), 'wb') as f:\n",
    "    pickle.dump(data_fully_available, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed775747",
   "metadata": {},
   "source": [
    "Checking if alignment was successful by calculating RSS between decades up to 2012: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965a230f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for 1800 - 1810 : 7133.27\n",
      "RSS for 1810 - 1820 : 8786.49\n",
      "RSS for 1820 - 1830 : 9558.01\n",
      "RSS for 1830 - 1840 : 9123.23\n",
      "RSS for 1840 - 1850 : 8810.37\n",
      "RSS for 1850 - 1860 : 8739.76\n",
      "RSS for 1860 - 1870 : 8727.94\n",
      "RSS for 1870 - 1880 : 8614.50\n",
      "RSS for 1880 - 1890 : 8706.18\n",
      "RSS for 1890 - 1900 : 8713.47\n",
      "RSS for 1900 - 1910 : 9109.31\n",
      "RSS for 1910 - 1920 : 9277.74\n",
      "RSS for 1920 - 1930 : 9470.97\n",
      "RSS for 1930 - 1940 : 9525.75\n",
      "RSS for 1940 - 1950 : 9614.07\n",
      "RSS for 1950 - 1960 : 9695.19\n",
      "RSS for 1960 - 1970 : 10018.94\n",
      "RSS for 1970 - 1980 : 10436.41\n",
      "RSS for 1980 - 1990 : 10656.92\n",
      "RSS for 1990 - 2012 : 11992.38\n"
     ]
    }
   ],
   "source": [
    "rss = 0\n",
    "\n",
    "for year in data_fully_available.keys():\n",
    "    matrix = data_fully_available[year].iloc[:, 1:]\n",
    "    if year != list(data_fully_available.keys())[0]:\n",
    "        previous_matrix = data_fully_available[previous_year].iloc[:, 1:]\n",
    "        rss += np.sum(np.square(matrix.to_numpy() - previous_matrix.to_numpy()))\n",
    "        print(\"RSS for {} - {} : {:.2f}\".format(previous_year, year, rss))\n",
    "    previous_year = year\n",
    "    rss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f50be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
