{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c908b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import diptest\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "NEIGHBORHOOD_SIZE = 30\n",
    "REGRESSION_MODEL_FILENAME = \"../regression_model.pkl\"\n",
    "BASEPATH_EMBEDDINGS = \"../resources/word_embeddings/\"\n",
    "FULLDATE_FILENAME = \"histWord_fullAvail_1800.pickle\"\n",
    "HISTORICAL_GOLDLABELS_PATH = \"../resources/historical_gold_lexicon/goldEN.vad\"\n",
    "\n",
    "#generated with ChatGPT\n",
    "def calculate_derivative(data, dx=1):\n",
    "    derivative = []\n",
    "    n = len(data)\n",
    "    for i in range(1, n - 1):\n",
    "        derivative_value = (data[i+1] - data[i-1]) / (2*dx)\n",
    "        derivative.append(derivative_value)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1c3b0",
   "metadata": {},
   "source": [
    "Load the word embeddings and regression model and predict valence-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0eecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(REGRESSION_MODEL_FILENAME), 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(BASEPATH_EMBEDDINGS, FULLDATE_FILENAME), 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "#data.append({})\n",
    "for year in data.keys():\n",
    "    embeds = data[year].iloc[:, 1:]\n",
    "    preds = model.predict(embeds)\n",
    "    data[year]['pred'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818bad8",
   "metadata": {},
   "source": [
    "Evaluate predictions on the historical lexicon provided by Buechel et al. (https://github.com/JULIELab/HistEmo) . Buechel et al. asked their historical language experts to label words from the perspective of someone living in the 1830s, therefore their labels will be compared against the 1830-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70f0f9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>valence_goldlabel</th>\n",
       "      <th>valence_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deal</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.350107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>study</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.121803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afford</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.279172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.875949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>height</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.066674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>walk</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.845415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>difference</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.176209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hang</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.983013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>following</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.809124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>employ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.562998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  valence_goldlabel  valence_predicted\n",
       "0         deal                5.5           5.350107\n",
       "1        study                5.5           6.121803\n",
       "2       afford                2.5           6.279172\n",
       "3      service                6.5           5.875949\n",
       "4       height                5.0           5.066674\n",
       "..         ...                ...                ...\n",
       "95        walk                6.0           5.845415\n",
       "96  difference                5.0           5.176209\n",
       "97        hang                5.0           4.983013\n",
       "98   following                4.0           5.809124\n",
       "99      employ                4.0           5.562998\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = [\"word\", \"valence_goldlabel\"]\n",
    "historical_goldlabels = pd.read_csv(HISTORICAL_GOLDLABELS_PATH, sep = \"\\t\", header = None, usecols = [0,1], names=colnames)\n",
    "\n",
    "predicted_goldlabels = pd.DataFrame({'word': list(data['1830']['word']), 'valence_predicted': data[\"1830\"][\"pred\"]})\n",
    "merged_df = pd.merge(historical_goldlabels, predicted_goldlabels, on='word')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bbcb8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.885"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['valence_goldlabel'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7460e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r of model: 0.5061797783040405\n"
     ]
    }
   ],
   "source": [
    "corr_coeff, p_value = pearsonr(merged_df['valence_goldlabel'], merged_df['valence_predicted'])\n",
    "print(\"Pearson's r of model: \" + str(corr_coeff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b645ef",
   "metadata": {},
   "source": [
    "Find k nearest neighbors in the embedding-space for each word in each decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fcc556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "closestNeighborsIdxs = {}\n",
    "\n",
    "for year in data.keys():\n",
    "    distances_between_vectors = pdist(data[year].iloc[:, 1:], metric=\"cosine\")\n",
    "    square_distance_matrix = squareform(distances_between_vectors)\n",
    "    x = np.argsort(square_distance_matrix, axis=1)[:,:NEIGHBORHOOD_SIZE].copy()\n",
    "    closestNeighborsIdxs[year] = x\n",
    "    distances_between_vectors, square_distance_matrix = [],[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15ec34",
   "metadata": {},
   "source": [
    "Calculate Hartigan's D for each word for each decade and also approximate and sum its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "027071d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for inspected_word in data['2012']['word']:\n",
    "    res[inspected_word] = [None, {}]\n",
    "    ps = []\n",
    "    for inspected_year in list(data.keys()):       \n",
    "        inspected_word_idx = list(data[inspected_year]['word']).index(inspected_word)\n",
    "        inspected_word_neighbord_idxs = closestNeighborsIdxs[inspected_year][inspected_word_idx]\n",
    "        x = data[inspected_year].iloc[list(inspected_word_neighbord_idxs), 301]\n",
    "        dip, pval = diptest.diptest(x)  \n",
    "        res[inspected_word][1][inspected_year] = (np.array(x), np.array(inspected_word_neighbord_idxs), pval)\n",
    "        ps.append(dip)\n",
    "    \n",
    "    derivative = np.abs(calculate_derivative(ps))\n",
    "    area_under_curve = sum(derivative)\n",
    "    res[inspected_word][0] = area_under_curve\n",
    "    \n",
    "sorted_dict = dict(sorted(res.items(), key=lambda x: x[1][0], reverse=True))\n",
    "top_words = list(sorted_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa744220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices and predicted valence of words are required for result object, word-embeddings can be discared\n",
    "data_min = {}\n",
    "for year in data.keys():\n",
    "    data_min[year] = data[year].iloc[:, [0,301]]\n",
    "\n",
    "#Save result object for later exploration\n",
    "with open(\"../results_k_{}.pkl\".format(NEIGHBORHOOD_SIZE), 'wb') as f:\n",
    "    pickle.dump([closestNeighborsIdxs, top_words, data_min], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61354f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
